{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyMwySvFWimJ21U0qGNKuP33",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shailavij/ML-Projects/blob/master/WindturbinePowerLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4SW_R_a72zY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import datetime\n",
        "import IPython\n",
        "import IPython.display\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import plotly.express as px\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "import keras \n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping \n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "\n",
        "\n",
        "mpl.rcParams['figure.figsize'] = (8, 6)\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "\n",
        "# to display all columns\n",
        "pd.options.display.max_columns = None\n",
        "pd.options.display.max_rows = None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "5XisaTgg8uG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_csv('/content/Turbine_Data.csv')\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "Z1TeCKph8F-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "Vo7YhMVk5EeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_updated= df[0:40000].copy()\n",
        "df_updated['Unnamed: 0']=pd.to_datetime(df_updated['Unnamed: 0'])\n",
        "df_updated.rename(columns={'Unnamed: 0':'date_column'},inplace=True)\n",
        "df_updated.head(2)"
      ],
      "metadata": {
        "id": "ouH2kZrH8YZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_updated.shape"
      ],
      "metadata": {
        "id": "yvF0YNWd5Mjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if (df_updated['Blade2PitchAngle'].equals(df_updated['Blade3PitchAngle'])==True):\n",
        "    df_updated = df_updated.drop('Blade3PitchAngle', axis=1)\n",
        "df_updated.info()"
      ],
      "metadata": {
        "id": "eZIUFd32dZ0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Chk for NULL value\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "vl4T9FkSdevn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "VivhCadedhpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To handle missing value using ffill method\n",
        "df_updated = df_updated.fillna(method='ffill').fillna(method='bfill')\n",
        "df_updated.isnull().sum()"
      ],
      "metadata": {
        "id": "ZHd1Rai6djAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(df_updated.corr())"
      ],
      "metadata": {
        "id": "QRkAM4fIdlit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting important feature\n",
        "df1 = df_updated[['date_column', 'WindSpeed', 'GeneratorRPM', 'ReactivePower', 'RotorRPM', 'AmbientTemperatue', \\\n",
        "                 'WindDirection', 'Blade1PitchAngle', 'Blade2PitchAngle', 'HubTemperature', 'MainBoxTemperature', 'GearboxBearingTemperature', \\\n",
        "                 'GearboxOilTemperature','NacellePosition','ActivePower']].copy()"
      ],
      "metadata": {
        "id": "pgYRw9Jfdody"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(df1.corr())"
      ],
      "metadata": {
        "id": "uf60PoC_dsXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2=df1.copy()"
      ],
      "metadata": {
        "id": "YtPiA5rwduK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fig = px.line(df2, x = 'date_column',y = 'ActivePower',title = 'windpower with slider')\n",
        "\n",
        "fig.update_xaxes(\n",
        "    rangeslider_visible= True,\n",
        "    rangeselector=dict(\n",
        "                        buttons = list([\n",
        "                        dict(count = 1,label = '1y',step='year',stepmode = \"backward\"),\n",
        "                        dict(count = 2,label = '2y',step='year',stepmode = \"backward\"),\n",
        "                        dict(count = 3,label = '3y',step='year',stepmode = \"backward\"),\n",
        "                        dict(step= 'all')\n",
        "                            ])        \n",
        "                        )\n",
        "                   )\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "vrNf-c4sdwef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.line(df2, x = 'date_column',y = 'GearboxOilTemperature',title = 'windpower with slider')\n",
        "\n",
        "fig.update_xaxes(\n",
        "    rangeslider_visible= True,\n",
        "    rangeselector=dict(\n",
        "                        buttons = list([\n",
        "                        dict(count = 1,label = '1y',step='year',stepmode = \"backward\"),\n",
        "                        dict(count = 2,label = '2y',step='year',stepmode = \"backward\"),\n",
        "                        dict(count = 3,label = '3y',step='year',stepmode = \"backward\"),\n",
        "                        dict(step= 'all')\n",
        "                            ])        \n",
        "                        )\n",
        "                   )\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "XPPrDwrQdy4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3= df2[3000:16000]\n",
        "df3.shape"
      ],
      "metadata": {
        "id": "Fr1J8Vhwd279"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4=df3[[ 'WindSpeed', 'GeneratorRPM',\n",
        "       'ReactivePower', 'RotorRPM', 'AmbientTemperatue', 'WindDirection',\n",
        "       'Blade1PitchAngle', 'Blade2PitchAngle', 'HubTemperature',\n",
        "       'MainBoxTemperature', 'GearboxBearingTemperature',\n",
        "       'GearboxOilTemperature', 'NacellePosition','ActivePower']]"
      ],
      "metadata": {
        "id": "g_WXu0rjd7I2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4.head(2)"
      ],
      "metadata": {
        "id": "e-zDgxEtd8yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.set(rc={'figure.figsize':(100,100)})\n",
        "\n",
        "sns.set(style=\"ticks\", color_codes=True)\n",
        "g = sns.pairplot(df4)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rokvhc19d-Wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From Pairplot,features like Reactivepower, Windspeed are highly correlated to ouput feature 'Active Power'\n",
        "\n",
        "Increase in Nacelleposition, WindDirection data also important feature to consider for 'Active power'"
      ],
      "metadata": {
        "id": "nuz9SEsreCiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Setindex Date&Timestamp\n",
        "df2.set_index('date_column',inplace=True)\n",
        "df2.head(2)"
      ],
      "metadata": {
        "id": "pr-gjk3FeAV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.shape"
      ],
      "metadata": {
        "id": "K3ISOmKJNEXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split the data**\n",
        "\n",
        "We will use 70%, 20%, 10% split for the training, validation and test sets."
      ],
      "metadata": {
        "id": "sZMjyLczeH20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "column_indices = {name: i for i, name in enumerate(df.columns)}\n",
        "\n",
        "n = len(df2)\n",
        "print(n)\n",
        "train_df = df2[0:int(n*0.7)]\n",
        "val_df = df2[int(n*0.7):int(n*0.9)]\n",
        "test_df = df2[int(n*0.9):]\n",
        "\n",
        "num_features = df2.shape[1]\n",
        "print(num_features)"
      ],
      "metadata": {
        "id": "TGeXEGuBeIcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.shape)\n",
        "print(val_df.shape)\n",
        "print(test_df.shape)"
      ],
      "metadata": {
        "id": "Pyi4IhI-eLpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scale the data using MinMax Scaler from -1 to 1 as LSTM has a default tanh activation function\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "SCALER = MinMaxScaler(feature_range=(-1,1))\n",
        "\n",
        "scaler = SCALER.fit(train_df.to_numpy())\n",
        "\n",
        "train_scaled = scaler.transform(train_df.to_numpy())\n",
        "test_scaled = scaler.transform(test_df.to_numpy())\n",
        "val_scaled = scaler.transform(val_df.to_numpy())"
      ],
      "metadata": {
        "id": "rAPXQPBCeN1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a function to split the datasets into two week windows\n",
        "timestep = 15*24*6 # 24hours,15days,6 (10 minutes sample per hour)\n",
        "\n",
        "def create_dataset(dataset, timestep=timestep):\n",
        "    \"\"\"\n",
        "    Function which creates two week chunks of x_train data, and a single\n",
        "    value for y_train.\n",
        "    \"\"\"\n",
        "    X, y = [], []\n",
        "    for i in range(len(dataset)):\n",
        "        target_value = i + timestep\n",
        "        if target_value == len(dataset):\n",
        "            break\n",
        "        feature_chunk, target = dataset[i:target_value, 1:], dataset[target_value, 0]\n",
        "        X.append(feature_chunk)\n",
        "        y.append(target)\n",
        "    \n",
        "    return np.array(X), np.array(y) "
      ],
      "metadata": {
        "id": "WkuROdVDePua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create x_train, y_train, X_test,y_test\n",
        "X_train, y_train = create_dataset(train_scaled)\n",
        "X_test, y_test = create_dataset(test_scaled)"
      ],
      "metadata": {
        "id": "sUfKOSrFeUBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "u2X5tjY6eUmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Creation"
      ],
      "metadata": {
        "id": "wJ2S2I4XehqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create X_train, y_train, X_test, y_test datasets\n",
        "# create a function to build a stacked LSTM model\n",
        "# input needs to be [samples, timesteps, features]\n",
        "def create_model(X_train, y_train):\n",
        "    units = 32\n",
        "    dropout = 0.05\n",
        "    epochs = 35\n",
        "    batch_size = 14\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.0005)\n",
        "    early_stopping = EarlyStopping(patience=7, monitor='loss')\n",
        "\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    model.add(LSTM(units=units, dropout=dropout, return_sequences=True,\n",
        "                   input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "\n",
        "    model.add(LSTM(units=units, dropout=dropout))\n",
        "\n",
        "    model.add(Dense(units=1))\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "    history = model.fit(X_train, y_train, validation_split=0.3, shuffle=False,\n",
        "              epochs=epochs, batch_size=batch_size, verbose=1, callbacks=[early_stopping])\n",
        "\n",
        "    return model, history"
      ],
      "metadata": {
        "id": "E6IercSleiRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to predict a single value \n",
        "def single_prediction(model, history, timestep=timestep):\n",
        "        \n",
        "        history = np.array(history)\n",
        "        history = history.reshape(history.shape[0]*history.shape[1], history.shape[2])\n",
        "        \n",
        "        input_value = history[-timestep:]\n",
        "        input_value = input_value.reshape(1, input_value.shape[0], input_value.shape[1])\n",
        "        \n",
        "        yhat = model.predict(input_value, verbose=0)\n",
        "        return yhat"
      ],
      "metadata": {
        "id": "rfsaxsV0eknS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function which takes first test chunk, makes a prediction, add the test chunk back into training data \n",
        "#to make next prediction\n",
        "\n",
        "def walk_forward_prediction(X_train, y_train, X_test, timestep):\n",
        "    \n",
        "    MODEL, history = create_model(X_train=X_train, y_train=y_train)\n",
        "    hist_train = [i for i in X_train]\n",
        "    predictions = []\n",
        "    \n",
        "    for i in range(len(X_test)):\n",
        "        test = X_test[i]\n",
        "        yhat = single_prediction(model=MODEL, history=hist_train, timestep=timestep)\n",
        "        predictions.append(yhat) \n",
        "        hist_train.append(test)\n",
        "    \n",
        "    return predictions, history, MODEL"
      ],
      "metadata": {
        "id": "cveveXN1emsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prior_inverse(features, targets):\n",
        "    '''\n",
        "    Append prediction value to test dataset and return a test shape format.\n",
        "    '''\n",
        "    dataset = []\n",
        "    \n",
        "    for i in range(features.shape[0]):\n",
        "        last_row, target = features[i][0], targets[i]\n",
        "        appended = np.append(last_row, target)\n",
        "        dataset.append(appended)\n",
        "    \n",
        "    return np.array(dataset) "
      ],
      "metadata": {
        "id": "EdDs3sEVe6su"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run experiemnt returning the real, predicted values\n",
        "def experiment(X_train, y_train, X_test, timestep):\n",
        "    \n",
        "    pred_seq, history, MODEL = walk_forward_prediction(X_train, y_train, X_test, timestep)\n",
        "    \n",
        "    pred_seq = np.array(pred_seq).reshape(-1)\n",
        "\n",
        "    pred = prior_inverse(X_test, pred_seq)\n",
        "    real = prior_inverse(X_test, y_test)\n",
        "\n",
        "    inv_pred = scaler.inverse_transform(pred)\n",
        "    inv_real = scaler.inverse_transform(real)\n",
        "\n",
        "    power_pred = inv_pred[:,-1]\n",
        "    power_real = inv_real[:,-1]\n",
        "    \n",
        "    return power_real, power_pred, history, MODEL"
      ],
      "metadata": {
        "id": "EacjvUN-e_RB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "power_real, power_pred, history, MODEL = experiment(X_train, y_train, X_test, timestep)\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']"
      ],
      "metadata": {
        "id": "DAOXZe3Ne_H8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot validation and training convergence graph\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(loss, label='train')\n",
        "plt.plot(val_loss, label='validation')\n",
        "plt.legend()\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('MSE')\n",
        "plt.title('LSTM Training Validation Loss')\n",
        "plt.tight_layout()\n",
        "plt.savefig('figures/train_val_plot.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "74XEQ92Te-9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XbPytBsgRu2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-eUiq9-Gh-pF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "import numpy as np\n",
        "data = np.array([[i] for i in range(50)])\n",
        "targets = np.array([[i] for i in range(50)])\n",
        "data_gen = TimeseriesGenerator(data, targets,\n",
        "                               length=10, sampling_rate=2,\n",
        "                               batch_size=2)\n",
        "\n",
        "assert len(data_gen) == 20\n",
        "batch_0 = data_gen[0]\n",
        "x, y = batch_0\n",
        "assert np.array_equal(x,\n",
        "                      np.array([[[0], [2], [4], [6], [8]],\n",
        "                                [[1], [3], [5], [7], [9]]]))\n",
        "assert np.array_equal(y,\n",
        "                      np.array([[10], [11]]))"
      ],
      "metadata": {
        "id": "YnS-5ydfh-ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "id": "hRO_7VhGi2Bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "id": "NxA2Ulgfi3iK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_gen[0]"
      ],
      "metadata": {
        "id": "zVRJ3reQh_z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_gen)"
      ],
      "metadata": {
        "id": "shrrbdzGiCqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "czRvgaJJiKHU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}